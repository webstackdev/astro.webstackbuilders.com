---
title: "Strangler Fig: Extracting Auth From a Monolith"
description: "A step-by-step walkthrough of extracting authentication into a separate service without downtime."
cover: "./cover.png"
coverAlt: "TODO"
author: "kevin-brown"
publishDate: 2024-01-15
tags: ["system-modernization"]
featured: true
---

*[API]: Application Programming Interface
*[CQRS]: Command Query Responsibility Segregation
*[CSRF]: Cross-Site Request Forgery
*[IdP]: Identity Provider
*[JWT]: JSON Web Token
*[MFA]: Multi-Factor Authentication
*[OIDC]: OpenID Connect
*[RBAC]: Role-Based Access Control
*[SAML]: Security Assertion Markup Language
*[SSO]: Single Sign-On
*[TOTP]: Time-based One-Time Password

Domain boundary identification, traffic routing, data migration, and the incremental steps that reduce risk.

Cut at the seams, not through the code.

## Why Auth Is the Hardest Extraction

Authentication touches everything, which makes it both the most valuable and most dangerous service to extract.

### The Auth Coupling Problem

Authentication in monoliths typically has tendrils throughout the codebase.

```typescript
// Typical monolith auth coupling points
interface AuthCouplingAnalysis {
  couplingPoint: string
  location: string
  migrationDifficulty: 'low' | 'medium' | 'high'
  strategy: string
}

const authCouplingPoints: AuthCouplingAnalysis[] = [
  {
    couplingPoint: 'User table foreign keys',
    location: 'Every table with user_id column',
    migrationDifficulty: 'high',
    strategy: 'Keep user IDs consistent, reference by ID not join'
  },
  {
    couplingPoint: 'Session storage',
    location: 'Shared database or in-memory store',
    migrationDifficulty: 'medium',
    strategy: 'Move to stateless JWT or external session store'
  },
  {
    couplingPoint: 'Permission checks',
    location: 'Scattered throughout business logic',
    migrationDifficulty: 'high',
    strategy: 'Extract to middleware, then to auth service'
  },
  {
    couplingPoint: 'User registration flows',
    location: 'Multiple controllers, email services',
    migrationDifficulty: 'medium',
    strategy: 'Consolidate to single entry point first'
  },
  {
    couplingPoint: 'Password reset/MFA',
    location: 'Dedicated controllers with email/SMS integration',
    migrationDifficulty: 'low',
    strategy: 'Clear boundary, extract early'
  },
  {
    couplingPoint: 'Audit logging',
    location: 'Joined with user data for display names',
    migrationDifficulty: 'medium',
    strategy: 'Denormalize user info into audit records'
  }
]
```

```
Mermaid diagram: Auth coupling in a typical monolith.
Monolith Application
├── Controllers (100+ files)
│   ├── All check req.user or req.session
│   └── Many have inline permission checks
│
├── Database
│   ├── users table (auth owns)
│   ├── sessions table (auth owns)
│   ├── orders table → user_id FK
│   ├── comments table → user_id FK
│   ├── audit_log table → user_id FK
│   └── (50+ more tables with user_id)
│
├── Services
│   ├── UserService (mixed auth + profile)
│   ├── EmailService (used by password reset)
│   └── AuditService (joins user names)
│
└── Middleware
    ├── AuthMiddleware (session validation)
    └── PermissionMiddleware (RBAC checks)

Every arrow is a coupling point that complicates extraction.
```

### Why Extract Auth First (or Not)

The arguments for and against starting with authentication.

| Factor | Auth First | Auth Later |
|--------|-----------|------------|
| Business value | High—enables SSO, better security | Higher—extract revenue-generating features |
| Risk | High—affects all users | Lower risk for other extractions |
| Complexity | High—touches everything | Lower if auth boundary is clean |
| Dependencies | Many—hard to isolate | Fewer once other services exist |
| Learning | Good—teaches the hardest case | Better to learn on easier extractions |

```typescript
// Decision framework
interface ExtractionDecision {
  extractAuthFirst: boolean
  reasoning: string[]
  prerequisites: string[]
}

function shouldExtractAuthFirst(context: MonolithContext): ExtractionDecision {
  const reasons: string[] = []
  const prerequisites: string[] = []

  // Reasons to extract auth first
  if (context.needsSSO || context.needsFederation) {
    reasons.push('Business requires SSO/federation capabilities')
  }
  if (context.securityAuditFindings.critical > 0) {
    reasons.push('Security audit requires auth modernization')
  }
  if (context.authCodeAge > years(5)) {
    reasons.push('Auth code is legacy and hard to maintain')
  }

  // Reasons to wait
  if (context.teamExperience.microservices === 'none') {
    reasons.push('Team should learn on easier extraction first')
    prerequisites.push('Complete one simpler service extraction')
  }
  if (!context.hasApiGateway) {
    prerequisites.push('Deploy API gateway/proxy first')
  }
  if (!context.hasObservability) {
    prerequisites.push('Add distributed tracing')
  }

  return {
    extractAuthFirst: reasons.length > 2 && prerequisites.length === 0,
    reasoning: reasons,
    prerequisites
  }
}
```

:::warning[Don't Start Here If You're New to Service Extraction]
Auth extraction is expert-level work. If your team hasn't extracted a service before, start with something simpler—a notification service, a reporting service, or a feature with clear boundaries. Learn the patterns before tackling auth.
:::

## Phase 1: Preparation and Boundary Definition

Work that must happen before writing any new code.

### Mapping the Auth Domain

Identifying everything that belongs to authentication.

```typescript
// Auth domain inventory
interface AuthDomainInventory {
  entities: EntityInventory[]
  operations: OperationInventory[]
  integrations: IntegrationInventory[]
  dataFlows: DataFlowInventory[]
}

// What data does auth own?
const entityInventory: EntityInventory[] = [
  {
    table: 'users',
    ownership: 'auth_owns',
    fields: {
      authOwned: ['id', 'email', 'password_hash', 'mfa_secret', 'last_login'],
      profileOwned: ['display_name', 'avatar_url', 'preferences'],
      decision: 'Split table—auth keeps credentials, profile service gets rest'
    }
  },
  {
    table: 'sessions',
    ownership: 'auth_owns',
    fields: {
      all: ['id', 'user_id', 'token', 'expires_at', 'created_at', 'ip_address']
    },
    decision: 'Move entirely to auth service, consider stateless JWT'
  },
  {
    table: 'roles',
    ownership: 'auth_owns',
    decision: 'Move to auth service'
  },
  {
    table: 'user_roles',
    ownership: 'auth_owns',
    decision: 'Move to auth service'
  },
  {
    table: 'permissions',
    ownership: 'auth_owns',
    decision: 'Move to auth service'
  },
  {
    table: 'oauth_connections',
    ownership: 'auth_owns',
    decision: 'Move to auth service'
  },
  {
    table: 'password_reset_tokens',
    ownership: 'auth_owns',
    decision: 'Move to auth service'
  }
]

// What operations does auth perform?
const operationInventory: OperationInventory[] = [
  { operation: 'Login (email/password)', frequency: 'high', owner: 'auth' },
  { operation: 'Login (OAuth)', frequency: 'medium', owner: 'auth' },
  { operation: 'Logout', frequency: 'high', owner: 'auth' },
  { operation: 'Register', frequency: 'medium', owner: 'auth' },
  { operation: 'Password reset request', frequency: 'low', owner: 'auth' },
  { operation: 'Password reset complete', frequency: 'low', owner: 'auth' },
  { operation: 'MFA enrollment', frequency: 'low', owner: 'auth' },
  { operation: 'MFA verification', frequency: 'high', owner: 'auth' },
  { operation: 'Session validation', frequency: 'very_high', owner: 'auth' },
  { operation: 'Permission check', frequency: 'very_high', owner: 'auth' },
  { operation: 'Token refresh', frequency: 'high', owner: 'auth' },
  { operation: 'API key validation', frequency: 'high', owner: 'auth' }
]
```

### Defining the Target API Contract

Designing the auth service interface before implementation.

```typescript
// Auth service API contract
interface AuthServiceContract {
  // Authentication endpoints
  authentication: {
    login: {
      method: 'POST'
      path: '/auth/login'
      request: { email: string; password: string; mfaCode?: string }
      response: { accessToken: string; refreshToken: string; expiresIn: number }
    }
    logout: {
      method: 'POST'
      path: '/auth/logout'
      request: { refreshToken: string }
      response: { success: boolean }
    }
    refresh: {
      method: 'POST'
      path: '/auth/refresh'
      request: { refreshToken: string }
      response: { accessToken: string; expiresIn: number }
    }
  }

  // Token validation (internal API, high frequency)
  validation: {
    validateToken: {
      method: 'POST'
      path: '/internal/validate'
      request: { token: string }
      response: {
        valid: boolean
        userId: string
        permissions: string[]
        expiresAt: number
      }
      slo: { latencyP99: '10ms', availability: '99.99%' }
    }
  }

  // User management
  users: {
    register: {
      method: 'POST'
      path: '/auth/register'
      request: { email: string; password: string; ... }
      response: { userId: string; verificationRequired: boolean }
    }
    verifyEmail: {
      method: 'POST'
      path: '/auth/verify-email'
      request: { token: string }
      response: { success: boolean }
    }
  }

  // Password management
  passwords: {
    requestReset: {
      method: 'POST'
      path: '/auth/password/reset-request'
      request: { email: string }
      response: { success: boolean }  // Always true to prevent enumeration
    }
    completeReset: {
      method: 'POST'
      path: '/auth/password/reset'
      request: { token: string; newPassword: string }
      response: { success: boolean }
    }
  }

  // MFA
  mfa: {
    enroll: {
      method: 'POST'
      path: '/auth/mfa/enroll'
      request: { type: 'totp' | 'sms' }
      response: { secret?: string; qrCode?: string }
    }
    verify: {
      method: 'POST'
      path: '/auth/mfa/verify'
      request: { code: string }
      response: { success: boolean; backupCodes?: string[] }
    }
  }
}
```

### Infrastructure Prerequisites

What must be in place before extraction begins.

```typescript
// Infrastructure checklist
const infrastructurePrerequisites = [
  {
    component: 'API Gateway / Reverse Proxy',
    purpose: 'Route requests between monolith and new auth service',
    options: ['Kong', 'NGINX', 'Envoy', 'AWS API Gateway'],
    requirement: 'Must support header-based routing and request transformation'
  },
  {
    component: 'Service discovery',
    purpose: 'Auth service needs to be discoverable',
    options: ['Consul', 'Kubernetes DNS', 'AWS Cloud Map'],
    requirement: 'Health checks and automatic failover'
  },
  {
    component: 'Distributed tracing',
    purpose: 'Debug requests spanning monolith and auth service',
    options: ['Jaeger', 'Zipkin', 'AWS X-Ray', 'Datadog APM'],
    requirement: 'Trace context propagation between services'
  },
  {
    component: 'Centralized logging',
    purpose: 'Correlate logs from both systems',
    options: ['ELK Stack', 'Loki', 'CloudWatch Logs'],
    requirement: 'Common request ID across services'
  },
  {
    component: 'Secret management',
    purpose: 'Auth service needs secure credential storage',
    options: ['HashiCorp Vault', 'AWS Secrets Manager', 'Azure Key Vault'],
    requirement: 'JWT signing keys, database credentials'
  }
]
```

```
Mermaid diagram: Infrastructure for auth extraction.
Internet
    ↓
API Gateway / Load Balancer
    ├── /auth/* → Auth Service (new)
    │              ├── Auth Database
    │              └── Redis (sessions/cache)
    │
    └── /* → Monolith (existing)
               ├── Monolith Database
               └── Calls Auth Service for validation

Both services:
- Report to distributed tracing
- Send logs to central aggregator
- Register with service discovery
- Pull secrets from vault
```

## Phase 2: Building the Auth Service

Implementing the new service while the monolith continues operating.

### Token Strategy: Sessions to JWTs

Migrating from server-side sessions to stateless tokens.

```typescript
// JWT structure for auth service
interface AuthTokenPayload {
  // Standard claims
  sub: string          // User ID
  iat: number          // Issued at
  exp: number          // Expiration
  iss: string          // Issuer (auth service)
  aud: string[]        // Audience (allowed services)

  // Custom claims
  email: string
  roles: string[]
  permissions: string[]
  orgId?: string       // For multi-tenant systems

  // Migration claims (temporary)
  legacySessionId?: string  // For dual-running
}

// Token service implementation
class TokenService {
  private readonly accessTokenTTL = 15 * 60        // 15 minutes
  private readonly refreshTokenTTL = 7 * 24 * 60 * 60  // 7 days

  async generateTokenPair(user: User): Promise<TokenPair> {
    const permissions = await this.getPermissions(user.id)

    const accessToken = jwt.sign(
      {
        sub: user.id,
        email: user.email,
        roles: user.roles,
        permissions,
        aud: ['api', 'internal']
      },
      this.privateKey,
      {
        algorithm: 'RS256',
        expiresIn: this.accessTokenTTL,
        issuer: 'auth-service'
      }
    )

    const refreshToken = await this.createRefreshToken(user.id)

    return {
      accessToken,
      refreshToken,
      expiresIn: this.accessTokenTTL
    }
  }

  async validateToken(token: string): Promise<ValidationResult> {
    try {
      const decoded = jwt.verify(token, this.publicKey, {
        algorithms: ['RS256'],
        issuer: 'auth-service'
      }) as AuthTokenPayload

      // Check if token has been revoked
      const isRevoked = await this.checkRevocation(decoded.sub, decoded.iat)
      if (isRevoked) {
        return { valid: false, reason: 'Token revoked' }
      }

      return {
        valid: true,
        userId: decoded.sub,
        email: decoded.email,
        roles: decoded.roles,
        permissions: decoded.permissions,
        expiresAt: decoded.exp
      }
    } catch (error) {
      return { valid: false, reason: error.message }
    }
  }

  // Refresh tokens are stored, not stateless
  private async createRefreshToken(userId: string): Promise<string> {
    const token = crypto.randomBytes(32).toString('hex')

    await this.refreshTokenStore.save({
      token: this.hashToken(token),
      userId,
      expiresAt: new Date(Date.now() + this.refreshTokenTTL * 1000),
      createdAt: new Date()
    })

    return token
  }
}
```

### Dual-Write Pattern for User Data

Keeping auth data in sync during migration.

```typescript
// Dual-write service for user changes
class DualWriteUserService {
  constructor(
    private monolithDb: Database,
    private authServiceClient: AuthServiceClient,
    private featureFlags: FeatureFlags
  ) {}

  async createUser(userData: CreateUserInput): Promise<User> {
    // Always write to monolith first (source of truth during migration)
    const monolithUser = await this.monolithDb.users.create({
      email: userData.email,
      passwordHash: await this.hashPassword(userData.password),
      displayName: userData.displayName,
      createdAt: new Date()
    })

    // Dual-write to auth service if enabled
    if (this.featureFlags.isEnabled('auth_dual_write')) {
      try {
        await this.authServiceClient.syncUser({
          id: monolithUser.id,
          email: monolithUser.email,
          passwordHash: monolithUser.passwordHash,
          createdAt: monolithUser.createdAt
        })
      } catch (error) {
        // Log but don't fail—monolith is still source of truth
        logger.error('Failed to sync user to auth service', {
          userId: monolithUser.id,
          error: error.message
        })

        // Queue for retry
        await this.syncQueue.add('sync_user', { userId: monolithUser.id })
      }
    }

    return monolithUser
  }

  async updatePassword(userId: string, newPassword: string): Promise<void> {
    const passwordHash = await this.hashPassword(newPassword)

    // Update monolith
    await this.monolithDb.users.update(
      { id: userId },
      { passwordHash, updatedAt: new Date() }
    )

    // Dual-write to auth service
    if (this.featureFlags.isEnabled('auth_dual_write')) {
      try {
        await this.authServiceClient.updateCredentials({
          userId,
          passwordHash
        })
      } catch (error) {
        logger.error('Failed to sync password to auth service', { userId })
        await this.syncQueue.add('sync_password', { userId })
      }
    }

    // Invalidate sessions in both systems
    await this.invalidateUserSessions(userId)
  }
}
```

```
Mermaid diagram: Dual-write data flow.
User Registration Request
         ↓
    Monolith
         ├── 1. Write to monolith DB (source of truth)
         │
         └── 2. Sync to Auth Service (async, retry on failure)
                    ↓
              Auth Service DB

During migration:
- Monolith DB is authoritative
- Auth Service DB is eventually consistent
- Sync failures are queued and retried
- Reconciliation job catches drift
```

### Data Migration Strategy

Moving existing user data without downtime.

```typescript
// Incremental data migration
interface MigrationConfig {
  batchSize: number
  rateLimit: number  // Records per second
  startFromId: string
  dryRun: boolean
}

class AuthDataMigration {
  async migrateUsers(config: MigrationConfig): Promise<MigrationReport> {
    const report: MigrationReport = {
      total: 0,
      migrated: 0,
      skipped: 0,
      failed: 0,
      errors: []
    }

    let lastId = config.startFromId

    while (true) {
      // Fetch batch from monolith
      const users = await this.monolithDb.query(`
        SELECT id, email, password_hash, created_at, mfa_secret, mfa_enabled
        FROM users
        WHERE id > $1
        ORDER BY id
        LIMIT $2
      `, [lastId, config.batchSize])

      if (users.length === 0) break

      for (const user of users) {
        report.total++

        try {
          // Check if already migrated
          const exists = await this.authService.userExists(user.id)
          if (exists) {
            report.skipped++
            continue
          }

          if (!config.dryRun) {
            await this.authService.importUser({
              id: user.id,
              email: user.email,
              passwordHash: user.password_hash,
              createdAt: user.created_at,
              mfaSecret: user.mfa_secret,
              mfaEnabled: user.mfa_enabled
            })
          }

          report.migrated++

          // Rate limiting
          await this.rateLimiter.wait(config.rateLimit)

        } catch (error) {
          report.failed++
          report.errors.push({
            userId: user.id,
            error: error.message
          })
        }

        lastId = user.id
      }

      // Checkpoint for resume
      await this.saveCheckpoint(lastId)

      logger.info('Migration progress', {
        lastId,
        migrated: report.migrated,
        total: report.total
      })
    }

    return report
  }

  async migrateRolesAndPermissions(): Promise<void> {
    // Migrate roles
    const roles = await this.monolithDb.query('SELECT * FROM roles')
    for (const role of roles) {
      await this.authService.importRole({
        id: role.id,
        name: role.name,
        description: role.description
      })
    }

    // Migrate permissions
    const permissions = await this.monolithDb.query('SELECT * FROM permissions')
    for (const permission of permissions) {
      await this.authService.importPermission({
        id: permission.id,
        name: permission.name,
        resource: permission.resource,
        action: permission.action
      })
    }

    // Migrate role-permission mappings
    const rolePermissions = await this.monolithDb.query(
      'SELECT * FROM role_permissions'
    )
    for (const rp of rolePermissions) {
      await this.authService.assignPermissionToRole({
        roleId: rp.role_id,
        permissionId: rp.permission_id
      })
    }

    // Migrate user-role mappings
    const userRoles = await this.monolithDb.query('SELECT * FROM user_roles')
    for (const ur of userRoles) {
      await this.authService.assignRoleToUser({
        userId: ur.user_id,
        roleId: ur.role_id
      })
    }
  }
}
```

## Phase 3: Traffic Migration

Gradually shifting authentication traffic to the new service.

### Router Configuration

Setting up the proxy to route auth requests.

```typescript
// Kong/NGINX routing configuration
const routingConfig = {
  // Phase 1: New registration goes to auth service
  phase1: {
    routes: [
      {
        path: '/auth/register',
        target: 'auth-service',
        condition: 'feature_flag:auth_register_new_service'
      }
    ],
    fallback: 'monolith'
  },

  // Phase 2: Add password reset
  phase2: {
    routes: [
      { path: '/auth/register', target: 'auth-service' },
      { path: '/auth/password/reset-request', target: 'auth-service' },
      { path: '/auth/password/reset', target: 'auth-service' }
    ],
    fallback: 'monolith'
  },

  // Phase 3: Add login (percentage-based)
  phase3: {
    routes: [
      { path: '/auth/register', target: 'auth-service' },
      { path: '/auth/password/*', target: 'auth-service' },
      {
        path: '/auth/login',
        target: 'auth-service',
        percentage: 10,  // Start with 10%
        stickyBy: 'user_id'
      }
    ],
    fallback: 'monolith'
  },

  // Phase 4: Full auth traffic
  phase4: {
    routes: [
      { path: '/auth/*', target: 'auth-service' }
    ],
    fallback: 'monolith'  // For non-auth routes
  }
}
```

```yaml
# Kong configuration example
services:
  - name: auth-service
    url: http://auth-service:8080

  - name: monolith
    url: http://monolith:8080

routes:
  # Auth service routes
  - name: auth-login
    service: auth-service
    paths:
      - /auth/login
    plugins:
      - name: canary
        config:
          percentage: 10
          upstream_fallback: monolith

  - name: auth-register
    service: auth-service
    paths:
      - /auth/register

  - name: auth-password
    service: auth-service
    paths:
      - /auth/password

  # Everything else to monolith
  - name: default
    service: monolith
    paths:
      - /
```

### Monolith Token Validation Adapter

Teaching the monolith to accept new tokens.

```typescript
// Adapter for monolith to validate auth service tokens
class AuthServiceAdapter {
  private authServiceUrl: string
  private cache: TokenCache
  private publicKey: string  // For local JWT validation

  constructor(config: AdapterConfig) {
    this.authServiceUrl = config.authServiceUrl
    this.cache = new TokenCache({ ttl: 60 })  // 60 second cache
    this.publicKey = config.jwtPublicKey
  }

  // Middleware for Express/Koa
  middleware() {
    return async (req: Request, res: Response, next: NextFunction) => {
      const token = this.extractToken(req)

      if (!token) {
        // Fall back to legacy session handling
        return this.legacySessionMiddleware(req, res, next)
      }

      try {
        const validation = await this.validateToken(token)

        if (!validation.valid) {
          return res.status(401).json({ error: 'Invalid token' })
        }

        // Attach user info to request (compatible with existing code)
        req.user = {
          id: validation.userId,
          email: validation.email,
          roles: validation.roles,
          permissions: validation.permissions
        }

        // Set legacy session properties for backward compatibility
        req.session = {
          userId: validation.userId,
          isAuthenticated: true
        }

        next()
      } catch (error) {
        logger.error('Token validation failed', { error: error.message })
        return res.status(500).json({ error: 'Authentication error' })
      }
    }
  }

  private async validateToken(token: string): Promise<ValidationResult> {
    // Check cache first
    const cached = await this.cache.get(token)
    if (cached) {
      return cached
    }

    // Try local validation first (faster)
    try {
      const decoded = jwt.verify(token, this.publicKey, {
        algorithms: ['RS256'],
        issuer: 'auth-service'
      }) as AuthTokenPayload

      const result: ValidationResult = {
        valid: true,
        userId: decoded.sub,
        email: decoded.email,
        roles: decoded.roles,
        permissions: decoded.permissions
      }

      await this.cache.set(token, result)
      return result

    } catch (localError) {
      // Fall back to auth service call (handles revocation)
      const response = await fetch(`${this.authServiceUrl}/internal/validate`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ token })
      })

      const result = await response.json()
      await this.cache.set(token, result)
      return result
    }
  }

  private extractToken(req: Request): string | null {
    // Check Authorization header
    const authHeader = req.headers.authorization
    if (authHeader?.startsWith('Bearer ')) {
      return authHeader.substring(7)
    }

    // Check cookie (for browser clients)
    return req.cookies?.access_token || null
  }
}
```

### Session Migration Path

Handling users who have active sessions during migration.

```typescript
// Session migration strategy
interface SessionMigrationStrategy {
  existingSessions: 'keep_valid' | 'force_reauth' | 'background_migrate'
  migrationTrigger: string
}

class SessionMigrationService {
  // Option 1: Keep existing sessions valid, issue new tokens on next login
  async keepExistingSessionsValid() {
    // Monolith continues to validate old sessions
    // New logins get JWT from auth service
    // Old sessions naturally expire
    return {
      pros: ['Zero disruption', 'Gradual migration'],
      cons: ['Must maintain dual validation', 'Longer migration window']
    }
  }

  // Option 2: Background migrate sessions to tokens
  async backgroundMigrateSessions() {
    const sessions = await this.monolithDb.query(`
      SELECT * FROM sessions
      WHERE expires_at > NOW()
      AND migrated = false
    `)

    for (const session of sessions) {
      // Create equivalent token in auth service
      const user = await this.getUser(session.user_id)
      const tokenPair = await this.authService.createTokensForMigration({
        userId: user.id,
        email: user.email,
        createdAt: session.created_at,
        expiresAt: session.expires_at  // Match original expiration
      })

      // Store mapping
      await this.sessionTokenMap.save({
        sessionId: session.id,
        accessToken: tokenPair.accessToken,
        refreshToken: tokenPair.refreshToken
      })

      // Mark as migrated
      await this.monolithDb.query(
        'UPDATE sessions SET migrated = true WHERE id = $1',
        [session.id]
      )
    }
  }

  // Middleware that transparently upgrades sessions to tokens
  upgradeMiddleware() {
    return async (req: Request, res: Response, next: NextFunction) => {
      // If request has old session but no token
      if (req.sessionID && !req.headers.authorization) {
        const mapping = await this.sessionTokenMap.getBySession(req.sessionID)

        if (mapping) {
          // Inject token into request
          req.headers.authorization = `Bearer ${mapping.accessToken}`

          // Set cookie for future requests
          res.cookie('access_token', mapping.accessToken, {
            httpOnly: true,
            secure: true,
            sameSite: 'strict'
          })
        }
      }

      next()
    }
  }
}
```

```
Mermaid diagram: Session migration timeline.
Day 0: Migration starts
       - Old sessions valid in monolith
       - New logins can go to either system

Day 1-7: Dual running
       - Background job migrates active sessions
       - Users with migrated sessions get JWT cookie
       - Non-migrated sessions still work

Day 7-14: Auth service primary
       - All new logins to auth service
       - Remaining old sessions expire naturally

Day 14+: Cutover complete
       - Session table deprecated
       - All auth through auth service
```

## Phase 4: Completion and Cutover

Finishing the migration and retiring monolith auth code.

### Validation and Reconciliation

Ensuring data consistency between systems.

```typescript
// Data reconciliation job
class AuthReconciliationJob {
  async reconcile(): Promise<ReconciliationReport> {
    const report: ReconciliationReport = {
      usersChecked: 0,
      mismatches: [],
      monolithOnly: [],
      authServiceOnly: [],
      fixed: 0
    }

    // Get all users from both systems
    const monolithUsers = await this.getMonolithUsers()
    const authServiceUsers = await this.getAuthServiceUsers()

    const monolithMap = new Map(monolithUsers.map(u => [u.id, u]))
    const authServiceMap = new Map(authServiceUsers.map(u => [u.id, u]))

    // Check monolith users exist in auth service
    for (const [id, monolithUser] of monolithMap) {
      report.usersChecked++

      const authUser = authServiceMap.get(id)

      if (!authUser) {
        report.monolithOnly.push(id)
        // Sync to auth service
        await this.syncUserToAuthService(monolithUser)
        report.fixed++
        continue
      }

      // Check for mismatches
      const mismatches = this.compareUsers(monolithUser, authUser)
      if (mismatches.length > 0) {
        report.mismatches.push({ userId: id, differences: mismatches })
        // Fix by syncing from monolith (source of truth during migration)
        await this.syncUserToAuthService(monolithUser)
        report.fixed++
      }
    }

    // Check for users only in auth service (shouldn't happen)
    for (const [id] of authServiceMap) {
      if (!monolithMap.has(id)) {
        report.authServiceOnly.push(id)
        logger.warn('User exists in auth service but not monolith', { userId: id })
      }
    }

    return report
  }

  private compareUsers(monolith: User, authService: User): string[] {
    const differences: string[] = []

    if (monolith.email !== authService.email) {
      differences.push(`email: ${monolith.email} vs ${authService.email}`)
    }
    if (monolith.passwordHash !== authService.passwordHash) {
      differences.push('password_hash mismatch')
    }
    if (monolith.mfaEnabled !== authService.mfaEnabled) {
      differences.push(`mfa_enabled: ${monolith.mfaEnabled} vs ${authService.mfaEnabled}`)
    }

    return differences
  }
}
```

### Feature Flag Driven Cutover

Using feature flags to control the final switch.

```typescript
// Feature flag progression for auth cutover
const cutoverFlags = {
  // Phase 1: Dual write
  'auth.dual_write.enabled': {
    defaultValue: false,
    description: 'Write auth changes to both monolith and auth service'
  },

  // Phase 2: Auth service for new users
  'auth.registration.use_auth_service': {
    defaultValue: false,
    description: 'New user registration handled by auth service'
  },

  // Phase 3: Auth service for login (percentage)
  'auth.login.auth_service_percentage': {
    defaultValue: 0,
    description: 'Percentage of login requests to route to auth service'
  },

  // Phase 4: Auth service for all auth
  'auth.all_requests.use_auth_service': {
    defaultValue: false,
    description: 'All auth requests handled by auth service'
  },

  // Phase 5: Disable monolith auth
  'auth.monolith.read_only': {
    defaultValue: false,
    description: 'Monolith auth code in read-only mode (no writes)'
  },

  // Phase 6: Remove monolith auth
  'auth.monolith.disabled': {
    defaultValue: false,
    description: 'Monolith auth code completely disabled'
  }
}

// Cutover controller
class CutoverController {
  async progressToNextPhase(): Promise<void> {
    const currentPhase = await this.getCurrentPhase()

    // Validation before progression
    const validation = await this.validatePhase(currentPhase)
    if (!validation.passed) {
      throw new Error(`Cannot progress: ${validation.reasons.join(', ')}`)
    }

    // Progress to next phase
    switch (currentPhase) {
      case 1:
        await this.featureFlags.enable('auth.dual_write.enabled')
        break
      case 2:
        await this.featureFlags.enable('auth.registration.use_auth_service')
        break
      case 3:
        // Gradual rollout
        const currentPct = await this.featureFlags.get('auth.login.auth_service_percentage')
        await this.featureFlags.set('auth.login.auth_service_percentage', currentPct + 10)
        break
      case 4:
        await this.featureFlags.enable('auth.all_requests.use_auth_service')
        break
      case 5:
        await this.featureFlags.enable('auth.monolith.read_only')
        break
      case 6:
        await this.featureFlags.enable('auth.monolith.disabled')
        break
    }

    logger.info('Progressed to phase', { phase: currentPhase + 1 })
  }

  async rollback(): Promise<void> {
    // Emergency rollback to monolith
    await this.featureFlags.disable('auth.all_requests.use_auth_service')
    await this.featureFlags.set('auth.login.auth_service_percentage', 0)

    logger.warn('Rolled back to monolith auth')
  }
}
```

### Removing Monolith Auth Code

Safely deleting the old implementation.

```typescript
// Code removal checklist
const codeRemovalChecklist = [
  {
    phase: 'Deprecation marking',
    actions: [
      'Add @deprecated JSDoc to all monolith auth functions',
      'Add console warnings when deprecated code is called',
      'Update documentation to point to auth service'
    ]
  },
  {
    phase: 'Dead code identification',
    actions: [
      'Enable logging on all auth endpoints',
      'Run for 2 weeks to confirm zero traffic',
      'Generate report of unused code paths'
    ]
  },
  {
    phase: 'Gradual removal',
    actions: [
      'Remove registration code first',
      'Remove password reset code',
      'Remove login code',
      'Remove session management',
      'Remove user table auth columns'
    ]
  },
  {
    phase: 'Database cleanup',
    actions: [
      'Archive sessions table',
      'Archive password_reset_tokens table',
      'Remove auth columns from users table',
      'Drop auth-related indexes'
    ]
  },
  {
    phase: 'Dependency cleanup',
    actions: [
      'Remove bcrypt/argon2 from monolith dependencies',
      'Remove JWT libraries if not used elsewhere',
      'Remove auth-related environment variables',
      'Update CI/CD to not run auth tests'
    ]
  }
]
```

:::success[Definition of Done]
Auth extraction is complete when: all auth traffic flows through the new service, monolith auth code is deleted, auth database tables are archived, and the team can deploy auth service independently without touching the monolith.
:::

## Rollback and Emergency Procedures

Handling problems during migration.

### Rollback Triggers

Conditions that should trigger automatic or manual rollback.

```typescript
// Rollback trigger definitions
interface RollbackTrigger {
  metric: string
  threshold: number
  action: 'alert' | 'auto_rollback'
  window: Duration
}

const rollbackTriggers: RollbackTrigger[] = [
  {
    metric: 'auth_service_error_rate',
    threshold: 0.01,  // 1% error rate
    action: 'auto_rollback',
    window: { minutes: 5 }
  },
  {
    metric: 'auth_service_latency_p99',
    threshold: 500,   // 500ms
    action: 'alert',
    window: { minutes: 5 }
  },
  {
    metric: 'login_success_rate',
    threshold: 0.95,  // Below 95% success
    action: 'auto_rollback',
    window: { minutes: 10 }
  },
  {
    metric: 'auth_service_availability',
    threshold: 0.999, // Below 99.9%
    action: 'auto_rollback',
    window: { minutes: 5 }
  }
]

// Rollback procedure
class RollbackProcedure {
  async executeRollback(trigger: RollbackTrigger): Promise<void> {
    logger.warn('Executing auth rollback', { trigger })

    // Step 1: Redirect traffic immediately
    await this.featureFlags.disable('auth.all_requests.use_auth_service')
    await this.featureFlags.set('auth.login.auth_service_percentage', 0)

    // Step 2: Verify monolith is handling traffic
    await this.verifyMonolithHealth()

    // Step 3: Alert on-call
    await this.pagerDuty.alert({
      severity: 'critical',
      title: 'Auth service rollback executed',
      description: `Trigger: ${trigger.metric} exceeded ${trigger.threshold}`
    })

    // Step 4: Log for post-mortem
    await this.incidentLog.create({
      type: 'auth_rollback',
      trigger,
      timestamp: new Date()
    })
  }
}
```

## Conclusion

Extracting authentication from a monolith is one of the hardest service extractions because auth touches everything. Success requires meticulous preparation: map every coupling point, define the API contract upfront, and ensure infrastructure prerequisites are in place. Use dual-write to keep data synchronized, with the monolith as source of truth until the auth service is proven. Migrate traffic incrementally—registration first, then password reset, then login at increasing percentages. Teach the monolith to validate new tokens while maintaining backward compatibility with sessions. Run reconciliation jobs to catch drift. Use feature flags to control every phase, with automatic rollback triggers when metrics degrade. The migration is complete only when monolith auth code is deleted, not just disabled. This is a multi-month effort for most teams—don't rush it.

---

## Cover Image Prompts

### Prompt 1: Key Being Extracted from Lock Mechanism
Close-up photograph of an ornate key being pulled from a complex mechanical lock, with the internal mechanism partially visible. Dramatic lighting highlighting the brass and steel components. The moment of extraction captured.

### Prompt 2: Surgical Extraction Scene
Stylized photograph of surgical instruments delicately extracting a component from a larger mechanism—precision tools, clean environment, careful hands. Medical/technical crossover aesthetic. The precision required for safe extraction.

### Prompt 3: Tree Root System Separation
Photograph or illustration of tree root systems being carefully separated—two plants that grew intertwined now being disentangled. Soil visible, roots clearly delineated. The organic metaphor for code entanglement.

### Prompt 4: Identity Document and Digital Code
Artistic photograph of a passport or identity document with holographic security features, overlaid with or transitioning into digital code/binary. The bridge between physical identity and digital authentication.

### Prompt 5: Vault Door Opening to New Space
Photograph of a massive bank vault door partially open, revealing a modern, clean, well-lit space beyond. The heavy old security transitioning to something new. Contrast between legacy protection and modern architecture.
