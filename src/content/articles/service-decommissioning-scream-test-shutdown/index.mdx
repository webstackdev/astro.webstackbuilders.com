---
title: "Decommissioning Services: The Art of Turning Off"
description: "Scream tests, traffic analysis, and soft shutdowns for services nobody remembers but everyone depends on."
cover: "./cover.jpg"
coverAlt: "TODO"
author: "kevin-brown"
publishDate: 2024-01-15
tags: ["system-modernization"]
featured: true
---

*[API]: Application Programming Interface
*[CDN]: Content Delivery Network
*[CNAME]: Canonical Name Record
*[DNS]: Domain Name System
*[ETL]: Extract, Transform, Load
*[MTTR]: Mean Time To Recovery
*[PII]: Personally Identifiable Information
*[RPS]: Requests Per Second
*[SLA]: Service Level Agreement
*[TTL]: Time To Live

Usage discovery, dependency mapping, shutdown sequencing, and the communication that prevents surprises.

Nobody knows what is used until you try to delete it.

## The Decommissioning Problem

Why turning services off is harder than turning them on, and why most organizations have more zombie services than they realize.

### The Cost of Not Decommissioning

Quantifying the ongoing expense of services nobody uses but everyone's afraid to delete.

```typescript
// Calculate the true cost of a zombie service
interface ZombieServiceCost {
  // Direct costs
  computeCost: number          // Monthly cloud spend
  storageCost: number          // Database, object storage
  licenseCost: number          // Third-party dependencies

  // Indirect costs
  securityRisk: number         // Unpatched vulnerabilities
  complianceRisk: number       // Audit surface area
  oncallBurden: number         // False alerts, confusion
  cognitiveLoad: number        // Mental overhead for team

  // Hidden costs
  blockedMigrations: number    // Services that can't upgrade because of dep
  slowDeployments: number      // CI/CD pipeline time
  testMaintenance: number      // Tests for unused code
}

function estimateZombieCost(service: Service): ZombieServiceCost {
  // Typical zombie service: $500-5000/month direct,
  // 2-10x that in indirect costs
  return {
    computeCost: estimateComputeCost(service),
    storageCost: estimateStorageCost(service),
    licenseCost: estimateLicenseCost(service),
    securityRisk: service.daysSinceLastPatch > 90 ? 2000 : 500,
    complianceRisk: service.handlesData ? 3000 : 500,
    oncallBurden: service.alertsPerMonth * 50, // $50 per false alert
    cognitiveLoad: 500, // Rough estimate per service
    blockedMigrations: countBlockedServices(service) * 1000,
    slowDeployments: service.ciMinutes * 0.01 * 30, // Per month
    testMaintenance: service.testCount * 2 // Hours per quarter
  }
}
```

| Cost Category | Low Estimate | High Estimate | Often Forgotten |
|---------------|--------------|---------------|-----------------|
| Compute | $100/mo | $5,000/mo | Idle resources still bill |
| Storage | $50/mo | $2,000/mo | Grows forever |
| Licenses | $0/mo | $10,000/mo | Per-seat or per-instance |
| Security patching | $200/mo | $2,000/mo | Unpatched = vulnerable |
| Cognitive overhead | $500/mo | $5,000/mo | Team confusion cost |

:::warning[Zombie Services Multiply]
Every zombie service makes the next decommissioning harder. They create phantom dependencies, confuse new engineers, and accumulate technical debt.
:::

### Why Decommissioning Is Scary

The psychological and organizational barriers that keep dead services running.

```
Mermaid diagram: Fear cascade preventing decommissioning.
"What if someone uses it?" ‚Üí No visibility into usage
  ‚Üì
"What if it breaks something?" ‚Üí Unknown dependencies
  ‚Üì
"Who owns the decision?" ‚Üí No clear authority
  ‚Üì
"What if we need it later?" ‚Üí Hoarding instinct
  ‚Üì
"It's not hurting anything" ‚Üí Cost invisibility
  ‚Üì
Service runs forever, accumulating cost and risk
```

The default is always "leave it running" because turning something off requires courage and knowledge that leaving it alone doesn't.

### Signs a Service Should Be Decommissioned

Indicators that a service is a decommissioning candidate.

```typescript
// Decommissioning candidate scoring
interface DecommissioningCandidate {
  serviceId: string
  score: number  // Higher = stronger candidate
  signals: DecommissioningSignal[]
}

interface DecommissioningSignal {
  type: SignalType
  weight: number
  evidence: string
}

type SignalType =
  | 'no-traffic'           // Zero requests
  | 'minimal-traffic'      // < 100 RPS
  | 'no-deploys'           // No deployments in 6+ months
  | 'no-code-changes'      // No commits in 12+ months
  | 'deprecated-upstream'  // Dependencies are EOL
  | 'no-owner'             // Team dissolved or left
  | 'replaced-by'          // Newer service does same thing
  | 'failed-feature'       // Feature never launched
  | 'one-time-migration'   // Migration job that finished
  | 'orphaned-data'        // Only serves old data

function scoreDecommissioningCandidate(
  service: Service
): DecommissioningCandidate {
  const signals: DecommissioningSignal[] = []

  // Traffic analysis
  const rps = getAverageRps(service.id, '30d')
  if (rps === 0) {
    signals.push({
      type: 'no-traffic',
      weight: 50,
      evidence: 'Zero requests in past 30 days'
    })
  } else if (rps < 0.01) {
    signals.push({
      type: 'minimal-traffic',
      weight: 30,
      evidence: `Only ${rps * 86400} requests per day`
    })
  }

  // Development activity
  const lastDeploy = getLastDeployDate(service.id)
  if (daysSince(lastDeploy) > 180) {
    signals.push({
      type: 'no-deploys',
      weight: 20,
      evidence: `No deployments since ${lastDeploy.toISOString()}`
    })
  }

  const lastCommit = getLastCommitDate(service.repository)
  if (daysSince(lastCommit) > 365) {
    signals.push({
      type: 'no-code-changes',
      weight: 15,
      evidence: `No commits since ${lastCommit.toISOString()}`
    })
  }

  // Ownership
  if (!service.owner || !teamExists(service.owner)) {
    signals.push({
      type: 'no-owner',
      weight: 25,
      evidence: 'No valid owner team assigned'
    })
  }

  return {
    serviceId: service.id,
    score: signals.reduce((sum, s) => sum + s.weight, 0),
    signals
  }
}
```

## The Scream Test: Controlled Failure

The safest way to discover if anyone uses a service: turn it off and wait for screams.

### Scream Test Design

Planning a scream test that reveals dependencies without causing lasting damage.

```
Mermaid diagram: Scream test phases.
Phase 0: Preparation (1-2 weeks)
- Announce planned test widely
- Set up rollback automation
- Configure monitoring
- Identify known consumers

Phase 1: Soft Degradation (1 week)
- Add latency (100ms ‚Üí 500ms ‚Üí 1s)
- Return deprecation headers
- Monitor for complaints

Phase 2: Intermittent Failures (1 week)
- Fail 1% ‚Üí 5% ‚Üí 10% of requests
- Return 503 with retry-after
- Monitor error rates in consumers

Phase 3: Hard Shutdown (1 week)
- Return 410 Gone for all requests
- Log all callers
- Wait for screams

Phase 4: Complete Removal (after quiet period)
- Remove from load balancer
- Delete compute resources
- Archive data (don't delete yet)
```

:::info[Always Announce First]
Send deprecation notices to every communication channel 2-4 weeks before starting. Some consumers will identify themselves, saving you discovery effort.
:::

```typescript
// Scream test controller
interface ScreamTestConfig {
  serviceId: string
  phases: ScreamTestPhase[]
  rollbackTriggers: RollbackTrigger[]
  notificationChannels: string[]
}

interface ScreamTestPhase {
  name: string
  duration: Duration
  behavior: PhaseBehavior
  successCriteria: string
}

type PhaseBehavior =
  | { type: 'add-latency'; latencyMs: number }
  | { type: 'fail-percentage'; percentage: number; statusCode: number }
  | { type: 'return-gone' }
  | { type: 'block-traffic' }

interface RollbackTrigger {
  condition: string  // PromQL or similar
  threshold: number
  action: 'pause' | 'rollback' | 'alert'
}

const exampleScreamTest: ScreamTestConfig = {
  serviceId: 'legacy-user-lookup',
  phases: [
    {
      name: 'degradation',
      duration: { days: 7 },
      behavior: { type: 'add-latency', latencyMs: 500 },
      successCriteria: 'No tickets, no escalations'
    },
    {
      name: 'intermittent-failure',
      duration: { days: 7 },
      behavior: { type: 'fail-percentage', percentage: 10, statusCode: 503 },
      successCriteria: 'Consumer error rates stable'
    },
    {
      name: 'hard-shutdown',
      duration: { days: 14 },
      behavior: { type: 'return-gone' },
      successCriteria: 'No new callers, no escalations'
    }
  ],
  rollbackTriggers: [
    {
      condition: 'rate(http_requests_total{service="legacy-user-lookup",status="5xx"}[5m]) > 100',
      threshold: 1,
      action: 'rollback'
    },
    {
      condition: 'alerts_firing{service="legacy-user-lookup",severity="critical"}',
      threshold: 1,
      action: 'pause'
    }
  ],
  notificationChannels: ['#platform-announce', '#legacy-migrations']
}
```

### Implementing Soft Shutdown Responses

Return responses that help consumers adapt rather than just failing.

```typescript
// Express middleware for scream test phases
function screamTestMiddleware(config: ScreamTestConfig) {
  return async (req: Request, res: Response, next: NextFunction) => {
    const phase = getCurrentPhase(config)

    // Always add deprecation headers
    res.set({
      'Deprecation': 'true',
      'Sunset': config.sunsetDate.toISOString(),
      'Link': `<${config.migrationGuide}>; rel="deprecation"`,
      'X-Decommission-Phase': phase.name,
      'X-Decommission-Contact': config.contactEmail
    })

    // Log every request for discovery
    logScreamTestRequest({
      service: config.serviceId,
      phase: phase.name,
      caller: identifyCaller(req),
      endpoint: req.path,
      method: req.method,
      userAgent: req.headers['user-agent'],
      timestamp: new Date()
    })

    switch (phase.behavior.type) {
      case 'add-latency':
        await sleep(phase.behavior.latencyMs)
        return next()

      case 'fail-percentage':
        if (Math.random() < phase.behavior.percentage / 100) {
          return res.status(phase.behavior.statusCode).json({
            error: 'Service is being decommissioned',
            migrationGuide: config.migrationGuide,
            retryAfter: 60,
            phase: phase.name
          })
        }
        return next()

      case 'return-gone':
        return res.status(410).json({
          error: 'Service has been decommissioned',
          migrationGuide: config.migrationGuide,
          contactEmail: config.contactEmail,
          alternatives: config.alternatives
        })

      case 'block-traffic':
        // Don't even respond, just drop
        req.socket.destroy()
        return
    }
  }
}

function identifyCaller(req: Request): CallerInfo {
  return {
    ip: req.ip,
    // Try to identify the calling service
    serviceHeader: req.headers['x-service-name'],
    userAgent: req.headers['user-agent'],
    // Trace context if available
    traceId: req.headers['x-trace-id'],
    // API key if used
    apiKey: req.headers['x-api-key']?.substring(0, 8) + '...',
    // mTLS client cert if available
    clientCert: req.socket.getPeerCertificate?.()?.subject?.CN
  }
}
```

### Scream Test Monitoring Dashboard

What to watch during a scream test.

```typescript
// Grafana dashboard panels for scream test
const screamTestDashboard = {
  title: 'Scream Test: ${service}',
  panels: [
    {
      title: 'Request Rate by Caller',
      type: 'timeseries',
      query: `
        sum(rate(scream_test_requests_total{service="${service}"}[5m]))
        by (caller_service)
      `
    },
    {
      title: 'Unique Callers',
      type: 'stat',
      query: `
        count(
          count by (caller_ip) (
            scream_test_requests_total{service="${service}"}
          )
        )
      `
    },
    {
      title: 'Error Rate in Downstream Services',
      type: 'timeseries',
      query: `
        sum(rate(http_requests_total{status=~"5.."}[5m]))
        by (service)
        # Filter to known consumers
      `
    },
    {
      title: 'Tickets and Escalations',
      type: 'table',
      // Link to Jira/ServiceNow query for related tickets
    },
    {
      title: 'Current Phase',
      type: 'stat',
      query: `scream_test_phase{service="${service}"}`
    },
    {
      title: 'Days Until Sunset',
      type: 'stat',
      query: `(scream_test_sunset_timestamp{service="${service}"} - time()) / 86400`
    }
  ],
  annotations: [
    { name: 'Phase Changes', query: 'scream_test_phase_change{service="${service}"}' },
    { name: 'Rollbacks', query: 'scream_test_rollback{service="${service}"}' },
    { name: 'Escalations', query: 'scream_test_escalation{service="${service}"}' }
  ]
}
```

## Traffic Analysis and Consumer Discovery

Finding out who uses a service before you try to turn it off.

### Passive Traffic Analysis

Discovering consumers through traffic observation without impacting the service.

```typescript
// Traffic analysis for consumer discovery
interface TrafficAnalysis {
  serviceId: string
  analysisWindow: Duration
  consumers: ConsumerProfile[]
  endpoints: EndpointUsage[]
  patterns: UsagePattern[]
}

interface ConsumerProfile {
  identifier: string          // IP, service name, API key
  identificationMethod: 'ip' | 'header' | 'mtls' | 'api-key' | 'trace'
  confidence: number
  traffic: {
    totalRequests: number
    requestsPerDay: number
    peakHour: number
    endpoints: string[]
  }
  characteristics: {
    userAgentPattern: string
    requestPatterns: string   // Batch? Real-time? Scheduled?
    errorHandling: string     // Do they retry? How?
  }
}

async function analyzeTraffic(
  serviceId: string,
  window: Duration
): Promise<TrafficAnalysis> {
  // Query access logs / service mesh telemetry
  const requests = await queryAccessLogs(serviceId, window)

  // Group by caller
  const callerGroups = groupBy(requests, identifyCaller)

  const consumers: ConsumerProfile[] = []

  for (const [callerId, callerRequests] of Object.entries(callerGroups)) {
    const requestsPerDay = callerRequests.length / window.days

    // Skip very low-volume callers (probably monitoring/health checks)
    if (requestsPerDay < 1) continue

    consumers.push({
      identifier: callerId,
      identificationMethod: determineIdMethod(callerId),
      confidence: calculateConfidence(callerRequests),
      traffic: {
        totalRequests: callerRequests.length,
        requestsPerDay,
        peakHour: findPeakHour(callerRequests),
        endpoints: [...new Set(callerRequests.map(r => r.path))]
      },
      characteristics: {
        userAgentPattern: extractUserAgentPattern(callerRequests),
        requestPatterns: classifyPattern(callerRequests),
        errorHandling: analyzeErrorHandling(callerRequests)
      }
    })
  }

  return {
    serviceId,
    analysisWindow: window,
    consumers: consumers.sort((a, b) => b.traffic.totalRequests - a.traffic.totalRequests),
    endpoints: analyzeEndpoints(requests),
    patterns: detectUsagePatterns(requests)
  }
}

function classifyPattern(requests: Request[]): string {
  const intervals = calculateRequestIntervals(requests)
  const avgInterval = mean(intervals)
  const stdDev = standardDeviation(intervals)

  // Very regular intervals = scheduled job
  if (stdDev / avgInterval < 0.1) {
    return `scheduled (every ${humanize(avgInterval)})`
  }

  // Bursts followed by silence = batch processing
  if (hasBurstPattern(intervals)) {
    return 'batch processing'
  }

  // Consistent throughout the day = real-time dependency
  if (isConsistentThroughDay(requests)) {
    return 'real-time dependency'
  }

  return 'irregular'
}
```

### Distributed Tracing for Dependency Discovery

Using trace data to find upstream and downstream dependencies.

```typescript
// Jaeger/Zipkin query for dependency discovery
async function discoverDependenciesFromTracing(
  serviceId: string,
  window: Duration
): Promise<DependencyDiscovery> {
  // Find all traces that include this service
  const traces = await queryTraces({
    service: serviceId,
    start: Date.now() - window.toMillis(),
    end: Date.now(),
    limit: 10000
  })

  const upstreamServices = new Map<string, UpstreamDependency>()
  const downstreamServices = new Map<string, DownstreamDependency>()

  for (const trace of traces) {
    // Find spans for our service
    const ourSpans = trace.spans.filter(s => s.service === serviceId)

    for (const span of ourSpans) {
      // Upstream: who called us
      const parentSpan = trace.spans.find(s => s.spanId === span.parentSpanId)
      if (parentSpan && parentSpan.service !== serviceId) {
        const existing = upstreamServices.get(parentSpan.service) || {
          service: parentSpan.service,
          callCount: 0,
          operations: new Set(),
          traceIds: []
        }
        existing.callCount++
        existing.operations.add(span.operationName)
        existing.traceIds.push(trace.traceId)
        upstreamServices.set(parentSpan.service, existing)
      }

      // Downstream: who do we call
      const childSpans = trace.spans.filter(
        s => s.parentSpanId === span.spanId && s.service !== serviceId
      )
      for (const child of childSpans) {
        const existing = downstreamServices.get(child.service) || {
          service: child.service,
          callCount: 0,
          operations: new Set(),
          criticalPath: false
        }
        existing.callCount++
        existing.operations.add(child.operationName)
        downstreamServices.set(child.service, existing)
      }
    }
  }

  return {
    serviceId,
    upstream: Array.from(upstreamServices.values()),
    downstream: Array.from(downstreamServices.values()),
    discoveryConfidence: calculateDiscoveryConfidence(traces.length)
  }
}
```

### Database Query Analysis

Finding what queries a service runs to understand data dependencies.

```typescript
// PostgreSQL pg_stat_statements analysis
async function analyzeDatabaseDependencies(
  serviceId: string
): Promise<DatabaseDependencies> {
  // Query pg_stat_statements for queries from this service
  // (requires application-level query tagging or connection pooler metadata)

  const queries = await db.query(`
    SELECT
      query,
      calls,
      total_time,
      rows,
      shared_blks_hit,
      shared_blks_read
    FROM pg_stat_statements
    WHERE query LIKE '%/* service:${serviceId} */%'
    ORDER BY calls DESC
    LIMIT 100
  `)

  const tableDependencies = new Map<string, TableUsage>()

  for (const q of queries.rows) {
    // Extract table names from query
    const tables = extractTableNames(q.query)
    const queryType = classifyQuery(q.query)

    for (const table of tables) {
      const existing = tableDependencies.get(table) || {
        table,
        readQueries: 0,
        writeQueries: 0,
        totalCalls: 0
      }

      existing.totalCalls += q.calls
      if (queryType === 'SELECT') {
        existing.readQueries += q.calls
      } else {
        existing.writeQueries += q.calls
      }

      tableDependencies.set(table, existing)
    }
  }

  return {
    serviceId,
    tables: Array.from(tableDependencies.values()),
    hasWriteDependencies: Array.from(tableDependencies.values())
      .some(t => t.writeQueries > 0)
  }
}
```

:::warning[Data Dependencies Are the Hardest]
A service might have zero traffic but still own critical data. Always check what tables/collections a service owns before decommissioning.
:::

## Communication and Stakeholder Management

The human side of decommissioning: getting buy-in and preventing surprises.

### Deprecation Announcement Template

Structured communication that covers all the bases.

```markdown
# Service Deprecation Notice: [Service Name]

## Summary
[Service Name] will be decommissioned on [Date]. This service [brief description of what it does].

## Timeline
- **Today**: Deprecation announced
- **[Date + 2 weeks]**: Soft degradation begins (added latency)
- **[Date + 4 weeks]**: Intermittent failures begin
- **[Date + 6 weeks]**: Service returns 410 Gone
- **[Date + 8 weeks]**: Infrastructure removed

## Migration Path
**If you consume this service:**
1. Identify your integration using [method]
2. Migrate to [alternative service/approach]
3. Update your code to handle deprecation responses
4. Contact [team] if you need migration assistance

**Migration guide:** [Link to detailed guide]
**Alternative service:** [Link to replacement service docs]

## Impact
- Services currently calling [Service Name]: [list known consumers]
- Data affected: [describe any data that will be archived/deleted]
- Cost savings: [estimated monthly savings]

## Support
- Questions: [Slack channel] or [email]
- Migration help: [calendar link for office hours]
- Escalation: [manager name] for business-critical concerns

## FAQ
**Q: What if I'm not ready by the deadline?**
A: Contact us at least 2 weeks before the deadline to discuss an extension.

**Q: What happens to the data?**
A: Data will be archived to [location] and retained for [period] before deletion.

**Q: Is there a replacement service?**
A: Yes, [alternative] provides equivalent functionality. See migration guide.
```

### Escalation Handling

Dealing with consumers who emerge during the scream test.

```typescript
// Escalation workflow
interface DecommissioningEscalation {
  serviceId: string
  reporter: {
    name: string
    team: string
    contact: string
  }
  urgency: 'blocking' | 'high' | 'medium' | 'low'
  impact: {
    description: string
    affectedUsers?: number
    revenueImpact?: number
    complianceImpact?: boolean
  }
  requestedAction: 'rollback' | 'extension' | 'assistance' | 'information'
  resolution?: EscalationResolution
}

type EscalationResolution =
  | { type: 'migration-completed'; migrationDate: Date }
  | { type: 'extension-granted'; newDeadline: Date; reason: string }
  | { type: 'rollback'; duration: Duration; reason: string }
  | { type: 'exception'; permanentException: boolean; reason: string }
  | { type: 'declined'; reason: string }

async function handleEscalation(
  escalation: DecommissioningEscalation
): Promise<EscalationResolution> {
  // Log for audit trail
  await logEscalation(escalation)

  // Auto-responses for common scenarios
  if (escalation.requestedAction === 'information') {
    await sendMigrationGuide(escalation.reporter)
    return { type: 'migration-completed', migrationDate: new Date() }
  }

  // Blocking escalations get immediate attention
  if (escalation.urgency === 'blocking') {
    // Pause scream test while investigating
    await pauseScreamTest(escalation.serviceId)
    await notifyDecommissioningTeam(escalation)

    // Create tracking ticket
    await createEscalationTicket(escalation)
  }

  // Extensions based on impact
  if (escalation.requestedAction === 'extension') {
    const extensionDays = calculateExtension(escalation.impact)

    if (extensionDays > 0) {
      await extendDeadline(escalation.serviceId, extensionDays)
      return {
        type: 'extension-granted',
        newDeadline: addDays(getCurrentDeadline(), extensionDays),
        reason: escalation.impact.description
      }
    }
  }

  // Fallback: human review
  return await requestHumanReview(escalation)
}

function calculateExtension(impact: EscalationImpact): number {
  if (impact.complianceImpact) return 30  // Compliance = automatic 30 days
  if (impact.revenueImpact && impact.revenueImpact > 10000) return 14
  if (impact.affectedUsers && impact.affectedUsers > 1000) return 7
  return 0
}
```

### Communication Timeline

A structured communication plan throughout the decommissioning process.

```
Mermaid diagram: Communication timeline.
Week -4: Initial announcement
- All-hands mention
- Slack announcement
- Email to known consumers
- Wiki page created

Week -2: Reminder + scream test start
- Reminder to all channels
- Direct outreach to identified consumers
- Scream test Phase 1 begins

Week -1: Weekly status
- Update on migration progress
- List of remaining consumers
- Office hours reminder

Week 0 (shutdown): Final notice
- 24-hour warning
- Final call for escalations
- Shutdown execution

Week +1: Post-shutdown
- Confirmation of successful shutdown
- Lessons learned
- Cost savings reported
```

## Shutdown Execution

The actual process of turning off a service safely.

### Shutdown Checklist

A comprehensive checklist for service shutdown.

```typescript
// Shutdown checklist items
interface ShutdownChecklist {
  preShutdown: ChecklistItem[]
  shutdown: ChecklistItem[]
  postShutdown: ChecklistItem[]
  cleanup: ChecklistItem[]
}

const standardShutdownChecklist: ShutdownChecklist = {
  preShutdown: [
    {
      item: 'All known consumers migrated',
      verification: 'Consumer tracking spreadsheet shows 0 remaining',
      required: true
    },
    {
      item: 'Scream test completed without blocking escalations',
      verification: 'Scream test dashboard shows all phases complete',
      required: true
    },
    {
      item: 'Data backup completed',
      verification: 'Backup verification script passes',
      required: true
    },
    {
      item: 'Rollback plan documented',
      verification: 'Rollback runbook reviewed and tested',
      required: true
    },
    {
      item: 'Stakeholder sign-off obtained',
      verification: 'Sign-off ticket approved',
      required: true
    },
    {
      item: 'Monitoring alerts silenced/removed',
      verification: 'No active alerts for service',
      required: true
    },
    {
      item: 'On-call team notified',
      verification: 'On-call channel acknowledgment',
      required: true
    }
  ],

  shutdown: [
    {
      item: 'Remove from load balancer',
      verification: 'No traffic reaching service',
      required: true
    },
    {
      item: 'Scale deployment to zero',
      verification: 'kubectl get pods shows 0 running',
      required: true
    },
    {
      item: 'Update DNS (if applicable)',
      verification: 'DNS returns NXDOMAIN or points to deprecation page',
      required: false
    },
    {
      item: 'Stop any scheduled jobs',
      verification: 'Cron/scheduler shows no pending runs',
      required: true
    },
    {
      item: 'Revoke service credentials',
      verification: 'Service account disabled',
      required: true
    }
  ],

  postShutdown: [
    {
      item: 'Monitor for unexpected errors',
      verification: '24h with no related errors in dependent services',
      required: true
    },
    {
      item: 'Confirm no traffic attempts',
      verification: 'Logs show no connection attempts',
      required: false
    },
    {
      item: 'Update service catalog',
      verification: 'Catalog shows service as decommissioned',
      required: true
    },
    {
      item: 'Update architecture diagrams',
      verification: 'Diagrams reviewed and updated',
      required: false
    }
  ],

  cleanup: [
    {
      item: 'Delete Kubernetes resources',
      verification: 'kubectl get all -l app=service shows nothing',
      required: true
    },
    {
      item: 'Delete/archive database',
      verification: 'Database marked for deletion after retention period',
      required: true
    },
    {
      item: 'Remove CI/CD pipelines',
      verification: 'Pipeline deleted or archived',
      required: true
    },
    {
      item: 'Archive source code repository',
      verification: 'Repo archived, not deleted',
      required: true
    },
    {
      item: 'Remove from monitoring',
      verification: 'Dashboards removed/archived',
      required: true
    },
    {
      item: 'Cancel related cloud resources',
      verification: 'Cloud console shows no related resources',
      required: true
    },
    {
      item: 'Update cost allocation',
      verification: 'FinOps confirms no ongoing charges',
      required: true
    }
  ]
}
```

### Automated Shutdown Script

Automating the repetitive parts of shutdown.

```typescript
// Shutdown automation
interface ShutdownConfig {
  serviceId: string
  dryRun: boolean
  skipConfirmation: boolean
  notificationChannels: string[]
}

async function executeShutdown(config: ShutdownConfig): Promise<ShutdownResult> {
  const steps: ShutdownStep[] = []

  console.log(`${config.dryRun ? '[DRY RUN] ' : ''}Starting shutdown of ${config.serviceId}`)

  // Step 1: Remove from load balancer
  steps.push(await executeStep({
    name: 'Remove from load balancer',
    execute: async () => {
      if (config.dryRun) return { success: true, message: 'Would remove from LB' }

      await kubectl(`patch ingress ${config.serviceId} -p '{"spec":{"rules":[]}}'`)
      return { success: true, message: 'Removed from ingress' }
    },
    rollback: async () => {
      await kubectl(`apply -f ingress-backup-${config.serviceId}.yaml`)
    }
  }))

  // Step 2: Scale to zero
  steps.push(await executeStep({
    name: 'Scale deployment to zero',
    execute: async () => {
      if (config.dryRun) return { success: true, message: 'Would scale to 0' }

      // Save current replica count for rollback
      const current = await kubectl(
        `get deployment ${config.serviceId} -o jsonpath='{.spec.replicas}'`
      )
      await saveRollbackState(config.serviceId, { replicas: current })

      await kubectl(`scale deployment ${config.serviceId} --replicas=0`)
      return { success: true, message: 'Scaled to 0 replicas' }
    },
    rollback: async () => {
      const state = await getRollbackState(config.serviceId)
      await kubectl(`scale deployment ${config.serviceId} --replicas=${state.replicas}`)
    }
  }))

  // Step 3: Disable scheduled jobs
  steps.push(await executeStep({
    name: 'Suspend cron jobs',
    execute: async () => {
      if (config.dryRun) return { success: true, message: 'Would suspend crons' }

      const cronjobs = await kubectl(
        `get cronjob -l app=${config.serviceId} -o name`
      )
      for (const cron of cronjobs.split('\n').filter(Boolean)) {
        await kubectl(`patch ${cron} -p '{"spec":{"suspend":true}}'`)
      }
      return { success: true, message: `Suspended ${cronjobs.length} cron jobs` }
    }
  }))

  // Step 4: Revoke service account
  steps.push(await executeStep({
    name: 'Disable service account',
    execute: async () => {
      if (config.dryRun) return { success: true, message: 'Would disable SA' }

      await kubectl(`delete serviceaccount ${config.serviceId}-sa`)
      return { success: true, message: 'Service account deleted' }
    }
  }))

  // Notify
  if (!config.dryRun) {
    for (const channel of config.notificationChannels) {
      await sendSlackMessage(channel, {
        text: `üîå Service ${config.serviceId} has been shut down`,
        blocks: [
          {
            type: 'section',
            text: { type: 'mrkdwn', text: `*Shutdown Complete: ${config.serviceId}*` }
          },
          {
            type: 'section',
            text: {
              type: 'mrkdwn',
              text: steps.map(s => `${s.success ? '‚úÖ' : '‚ùå'} ${s.name}`).join('\n')
            }
          }
        ]
      })
    }
  }

  return {
    serviceId: config.serviceId,
    success: steps.every(s => s.success),
    steps,
    timestamp: new Date()
  }
}
```

### Rollback Procedures

When the scream test screams too loudly.

```typescript
// Rollback automation
interface RollbackConfig {
  serviceId: string
  reason: string
  triggeredBy: 'automatic' | 'manual'
  triggerCondition?: string
}

async function executeRollback(config: RollbackConfig): Promise<RollbackResult> {
  console.log(`‚ö†Ô∏è Rolling back shutdown of ${config.serviceId}`)
  console.log(`Reason: ${config.reason}`)

  // Alert the team
  await sendUrgentNotification({
    title: `Rollback: ${config.serviceId}`,
    message: `Shutdown rolled back due to: ${config.reason}`,
    severity: 'high'
  })

  const state = await getRollbackState(config.serviceId)

  // Restore in reverse order

  // 1. Restore service account
  if (state.serviceAccount) {
    await kubectl(`apply -f ${state.serviceAccount}`)
  }

  // 2. Unsuspend cron jobs
  for (const cron of state.cronJobs || []) {
    await kubectl(`patch cronjob ${cron} -p '{"spec":{"suspend":false}}'`)
  }

  // 3. Scale back up
  await kubectl(
    `scale deployment ${config.serviceId} --replicas=${state.replicas}`
  )

  // 4. Restore load balancer config
  await kubectl(`apply -f ${state.ingressConfig}`)

  // 5. Wait for pods to be ready
  await kubectl(
    `wait --for=condition=ready pod -l app=${config.serviceId} --timeout=300s`
  )

  // 6. Verify health
  const healthCheck = await verifyServiceHealth(config.serviceId)

  // Create incident for investigation
  await createIncident({
    title: `Decommissioning rollback: ${config.serviceId}`,
    severity: 'medium',
    description: `
      Decommissioning of ${config.serviceId} was rolled back.

      Reason: ${config.reason}
      Trigger: ${config.triggeredBy}
      ${config.triggerCondition ? `Condition: ${config.triggerCondition}` : ''}

      Action needed: Investigate consumers and update migration plan.
    `
  })

  return {
    serviceId: config.serviceId,
    success: healthCheck.healthy,
    restoredAt: new Date(),
    healthStatus: healthCheck
  }
}
```

## Data Handling During Decommissioning

What to do with the data when the service goes away.

### Data Retention Strategy

Balancing compliance requirements with cleanup goals.

```typescript
// Data retention policy
interface DataRetentionPolicy {
  dataType: string
  retentionPeriod: Duration
  archiveLocation: string
  deletionApproval: 'automatic' | 'manual'
  complianceRequirements: string[]
}

const standardRetentionPolicies: DataRetentionPolicy[] = [
  {
    dataType: 'user-pii',
    retentionPeriod: { years: 7 },
    archiveLocation: 'cold-storage-encrypted',
    deletionApproval: 'manual',
    complianceRequirements: ['GDPR', 'CCPA', 'SOX']
  },
  {
    dataType: 'transaction-records',
    retentionPeriod: { years: 7 },
    archiveLocation: 'cold-storage-encrypted',
    deletionApproval: 'manual',
    complianceRequirements: ['SOX', 'PCI-DSS']
  },
  {
    dataType: 'application-logs',
    retentionPeriod: { days: 90 },
    archiveLocation: 'log-archive',
    deletionApproval: 'automatic',
    complianceRequirements: []
  },
  {
    dataType: 'configuration',
    retentionPeriod: { years: 1 },
    archiveLocation: 'config-archive',
    deletionApproval: 'automatic',
    complianceRequirements: []
  },
  {
    dataType: 'source-code',
    retentionPeriod: { forever: true },
    archiveLocation: 'archived-repos',
    deletionApproval: 'manual',
    complianceRequirements: ['IP-retention']
  }
]

async function archiveServiceData(
  serviceId: string,
  policies: DataRetentionPolicy[]
): Promise<ArchiveResult> {
  const results: DataArchiveResult[] = []

  for (const policy of policies) {
    const data = await identifyData(serviceId, policy.dataType)

    if (data.size === 0) continue

    // Archive to appropriate location
    const archivePath = await archiveData({
      source: data.location,
      destination: `${policy.archiveLocation}/${serviceId}/${policy.dataType}`,
      encryption: policy.dataType.includes('pii') ? 'AES-256' : 'none',
      compression: true
    })

    // Schedule deletion
    const deletionDate = addDuration(new Date(), policy.retentionPeriod)

    await scheduleDeletion({
      archivePath,
      deletionDate,
      requiresApproval: policy.deletionApproval === 'manual',
      compliance: policy.complianceRequirements
    })

    results.push({
      dataType: policy.dataType,
      size: data.size,
      archivePath,
      scheduledDeletion: deletionDate
    })
  }

  return {
    serviceId,
    archivedAt: new Date(),
    archives: results,
    totalSize: results.reduce((sum, r) => sum + r.size, 0)
  }
}
```

### Database Archival Process

Safely archiving database data before deletion.

```typescript
// Database archival workflow
async function archiveDatabase(
  serviceId: string,
  database: DatabaseInfo
): Promise<DatabaseArchiveResult> {
  // 1. Take final backup
  const backupId = await createDatabaseBackup(database, {
    type: 'final',
    label: `decommission-${serviceId}-${Date.now()}`
  })

  // 2. Verify backup integrity
  const verificationResult = await verifyBackup(backupId)
  if (!verificationResult.valid) {
    throw new Error(`Backup verification failed: ${verificationResult.error}`)
  }

  // 3. Export to portable format (Parquet/CSV for analytics access)
  const exportPath = await exportToParquet(database, {
    destination: `s3://data-archive/${serviceId}/`,
    partitionBy: 'year',
    includeSchema: true
  })

  // 4. Document the archive
  const manifest: ArchiveManifest = {
    serviceId,
    database: database.name,
    archivedAt: new Date(),
    backupId,
    exportPath,
    schema: await extractSchema(database),
    rowCounts: await getTableRowCounts(database),
    retentionPolicy: determineRetentionPolicy(database),
    accessInstructions: generateAccessInstructions(exportPath)
  }

  await saveManifest(manifest)

  // 5. Set deletion timer (don't delete immediately)
  await scheduleResourceDeletion({
    resourceType: 'database',
    resourceId: database.id,
    deletionDate: addDays(new Date(), 30), // 30-day grace period
    prerequisite: 'archive-verified',
    notifyBefore: [7, 1] // Days before deletion
  })

  return {
    success: true,
    backupId,
    exportPath,
    manifest
  }
}
```

:::danger[Never Delete Data Without Archive Verification]
Always verify archives are accessible and complete before deleting source data. The 30-day grace period has saved many teams from disaster.
:::

## Post-Decommissioning

What happens after the service is gone.

### Cleanup Verification

Confirming all resources are actually gone.

```typescript
// Resource cleanup verification
interface CleanupVerification {
  resourceType: string
  expectedState: 'deleted' | 'archived' | 'transferred'
  verificationMethod: () => Promise<boolean>
}

async function verifyCleanup(serviceId: string): Promise<CleanupReport> {
  const verifications: CleanupVerification[] = [
    {
      resourceType: 'kubernetes-deployment',
      expectedState: 'deleted',
      verificationMethod: async () => {
        const result = await kubectl(`get deployment ${serviceId} 2>&1`)
        return result.includes('NotFound')
      }
    },
    {
      resourceType: 'kubernetes-service',
      expectedState: 'deleted',
      verificationMethod: async () => {
        const result = await kubectl(`get service ${serviceId} 2>&1`)
        return result.includes('NotFound')
      }
    },
    {
      resourceType: 'database',
      expectedState: 'archived',
      verificationMethod: async () => {
        const archive = await checkArchiveExists(serviceId)
        const dbDeleted = !(await databaseExists(serviceId))
        return archive && dbDeleted
      }
    },
    {
      resourceType: 'dns-records',
      expectedState: 'deleted',
      verificationMethod: async () => {
        const records = await getDnsRecords(serviceId)
        return records.length === 0
      }
    },
    {
      resourceType: 'ssl-certificates',
      expectedState: 'deleted',
      verificationMethod: async () => {
        const certs = await getCertificates(serviceId)
        return certs.length === 0
      }
    },
    {
      resourceType: 'cloud-resources',
      expectedState: 'deleted',
      verificationMethod: async () => {
        const resources = await findCloudResources({ tag: `service:${serviceId}` })
        return resources.length === 0
      }
    },
    {
      resourceType: 'ci-pipelines',
      expectedState: 'archived',
      verificationMethod: async () => {
        const pipeline = await getPipeline(serviceId)
        return pipeline?.status === 'archived'
      }
    },
    {
      resourceType: 'monitoring',
      expectedState: 'deleted',
      verificationMethod: async () => {
        const dashboards = await findDashboards(serviceId)
        const alerts = await findAlerts(serviceId)
        return dashboards.length === 0 && alerts.length === 0
      }
    }
  ]

  const results: VerificationResult[] = []

  for (const v of verifications) {
    const passed = await v.verificationMethod()
    results.push({
      resourceType: v.resourceType,
      expectedState: v.expectedState,
      passed,
      checkedAt: new Date()
    })

    if (!passed) {
      console.warn(`‚ö†Ô∏è ${v.resourceType} not in expected state (${v.expectedState})`)
    }
  }

  return {
    serviceId,
    allPassed: results.every(r => r.passed),
    results,
    reportedAt: new Date()
  }
}
```

### Cost Savings Validation

Proving the value of decommissioning.

```typescript
// Cost savings tracking
interface CostSavingsReport {
  serviceId: string
  decommissionedAt: Date

  beforeCosts: {
    compute: number
    storage: number
    network: number
    licenses: number
    total: number
    period: 'monthly'
  }

  afterCosts: {
    archiveStorage: number
    total: number
    period: 'monthly'
  }

  savings: {
    monthly: number
    annual: number
    percentReduction: number
  }

  hiddenSavings: {
    securityRiskReduction: string
    complianceScopeReduction: string
    operationalOverheadReduction: string
  }
}

async function calculateCostSavings(serviceId: string): Promise<CostSavingsReport> {
  // Get historical costs (before decommissioning)
  const historicalCosts = await getHistoricalCosts(serviceId, '3m')
  const avgMonthlyBefore = average(historicalCosts.map(c => c.total))

  // Get current costs (archive storage only)
  const currentCosts = await getCurrentCosts(serviceId)

  const monthlySavings = avgMonthlyBefore - currentCosts.total

  return {
    serviceId,
    decommissionedAt: await getDecommissionDate(serviceId),
    beforeCosts: {
      compute: average(historicalCosts.map(c => c.compute)),
      storage: average(historicalCosts.map(c => c.storage)),
      network: average(historicalCosts.map(c => c.network)),
      licenses: average(historicalCosts.map(c => c.licenses)),
      total: avgMonthlyBefore,
      period: 'monthly'
    },
    afterCosts: {
      archiveStorage: currentCosts.total,
      total: currentCosts.total,
      period: 'monthly'
    },
    savings: {
      monthly: monthlySavings,
      annual: monthlySavings * 12,
      percentReduction: (monthlySavings / avgMonthlyBefore) * 100
    },
    hiddenSavings: {
      securityRiskReduction: 'One less service to patch and monitor',
      complianceScopeReduction: 'Reduced audit surface area',
      operationalOverheadReduction: 'No more false alerts or on-call burden'
    }
  }
}
```

### Lessons Learned Documentation

Capturing what worked and what didn't for the next decommissioning.

```typescript
// Post-decommissioning retrospective template
interface DecommissioningRetrospective {
  serviceId: string
  duration: {
    planningToShutdown: Duration
    plannedDuration: Duration
    actualDuration: Duration
    delay: Duration
  }

  whatWorked: string[]
  whatDidntWork: string[]
  surprises: string[]

  consumerDiscovery: {
    knownBefore: number
    discoveredDuring: number
    discoveryMethods: string[]
  }

  escalations: {
    count: number
    categories: string[]
    resolutions: string[]
  }

  recommendations: string[]

  metrics: {
    totalCostSaved: number
    engineeringHoursSpent: number
    roi: number
  }
}

// Example retrospective
const exampleRetro: DecommissioningRetrospective = {
  serviceId: 'legacy-user-service',
  duration: {
    planningToShutdown: { weeks: 8 },
    plannedDuration: { weeks: 6 },
    actualDuration: { weeks: 10 },
    delay: { weeks: 4 }
  },
  whatWorked: [
    'Early announcement gave teams time to plan migrations',
    'Scream test caught 3 unknown consumers before hard shutdown',
    'Automated rollback saved us during unexpected escalation',
    'Weekly status updates kept stakeholders informed'
  ],
  whatDidntWork: [
    'Initial consumer list was incomplete (missed batch jobs)',
    'Data archival took longer than expected due to compliance review',
    'Some teams ignored deprecation warnings until scream test started'
  ],
  surprises: [
    'Marketing had an undocumented integration via spreadsheet export',
    'Old mobile app version still calling deprecated endpoints',
    'Database had foreign key constraints to other services'
  ],
  consumerDiscovery: {
    knownBefore: 5,
    discoveredDuring: 3,
    discoveryMethods: ['traffic analysis', 'scream test', 'escalation']
  },
  escalations: {
    count: 4,
    categories: ['migration assistance', 'extension request', 'data access'],
    resolutions: ['migration completed', '2-week extension', 'archive access granted']
  },
  recommendations: [
    'Start traffic analysis 4 weeks before announcement',
    'Include batch job discovery in standard process',
    'Add database foreign key analysis to checklist',
    'Require explicit acknowledgment from known consumers'
  ],
  metrics: {
    totalCostSaved: 3500,  // Monthly
    engineeringHoursSpent: 80,
    roi: (3500 * 12) / (80 * 150)  // 3.5x ROI in first year
  }
}
```

## Conclusion

Decommissioning services requires more planning than building them. The scream test is the safest discovery mechanism‚Äîannounce deprecation, add latency, introduce failures, then shut down, giving consumers time to identify themselves at each stage. Traffic analysis, distributed tracing, and database query logging help discover consumers before the scream test begins. Communication is critical: announce early, remind often, and provide clear migration paths. Never delete data without verified archives and retention period compliance. The ROI of decommissioning is substantial‚Äînot just in direct cost savings but in reduced security surface, compliance scope, and operational overhead. Document every decommissioning for the team that does the next one.

---

## Cover Image Prompts

### Prompt 1: Industrial Shutdown Sequence
Photograph of an industrial control panel with illuminated switches and buttons, some in the off position with red indicators. Steam or mist in the background suggesting shutdown of machinery. Dramatic low-key lighting with highlights on the metal switches. The sense of controlled, deliberate deactivation.

### Prompt 2: Unplugged Server Cables
Close-up photograph of disconnected ethernet and power cables hanging loose against a server rack background. Shallow depth of field with the disconnected ends in sharp focus. Cool blue data center lighting with warm accent from status LEDs on distant equipment. The finality of disconnection.

### Prompt 3: Fading Signal Visualization
Abstract visualization of a signal or waveform gradually fading from strong to flat. Left side shows vibrant, active waveform in bright colors (green/cyan). Right side shows the same signal diminishing through yellow to orange to a flat red line. Clean dark background with subtle grid suggesting monitoring interface.

### Prompt 4: Demolition in Progress
Architectural photograph of a building mid-demolition, showing the controlled nature of the process. Partial structure remaining with clean cuts where sections have been removed. Clear blue sky contrasting with the industrial scene. The idea of planned, methodical removal rather than destruction.

### Prompt 5: Archive Storage Facility
Photograph of long rows of archive storage boxes on industrial shelving, extending into the distance with dramatic perspective. Warm incandescent lighting creating pools of light between shadows. Labels visible on nearest boxes suggesting organized retirement. The sense of data preserved but no longer active.
